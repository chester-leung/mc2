{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secure XGBoost Tutorial\n",
    "#### RISE Camp tutorial on the Secure XGBoost project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Party XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in and examine our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>25.23214</td>\n",
       "      <td>-232.77465</td>\n",
       "      <td>-37.51542</td>\n",
       "      <td>-40.34335</td>\n",
       "      <td>56.11564</td>\n",
       "      <td>-55.94831</td>\n",
       "      <td>43.06882</td>\n",
       "      <td>15.46278</td>\n",
       "      <td>-38.67370</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.64058</td>\n",
       "      <td>257.69408</td>\n",
       "      <td>113.59740</td>\n",
       "      <td>-90.14988</td>\n",
       "      <td>-13.41911</td>\n",
       "      <td>-72.59105</td>\n",
       "      <td>-185.49959</td>\n",
       "      <td>1.16272</td>\n",
       "      <td>-73.13128</td>\n",
       "      <td>-6.89193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>27.96974</td>\n",
       "      <td>-166.08713</td>\n",
       "      <td>-11.19265</td>\n",
       "      <td>-28.07397</td>\n",
       "      <td>-56.10902</td>\n",
       "      <td>-35.47258</td>\n",
       "      <td>23.35854</td>\n",
       "      <td>7.19973</td>\n",
       "      <td>-36.81179</td>\n",
       "      <td>...</td>\n",
       "      <td>21.49227</td>\n",
       "      <td>289.05914</td>\n",
       "      <td>-34.75972</td>\n",
       "      <td>-19.38242</td>\n",
       "      <td>2.44006</td>\n",
       "      <td>-67.78591</td>\n",
       "      <td>-46.62749</td>\n",
       "      <td>0.38383</td>\n",
       "      <td>98.98315</td>\n",
       "      <td>13.14364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2007</td>\n",
       "      <td>24.75152</td>\n",
       "      <td>-97.45055</td>\n",
       "      <td>-40.15226</td>\n",
       "      <td>-43.39929</td>\n",
       "      <td>-57.25665</td>\n",
       "      <td>-33.93026</td>\n",
       "      <td>-1.95605</td>\n",
       "      <td>0.93121</td>\n",
       "      <td>7.76578</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.96584</td>\n",
       "      <td>573.94557</td>\n",
       "      <td>11.83355</td>\n",
       "      <td>-107.81947</td>\n",
       "      <td>-3.42495</td>\n",
       "      <td>-141.79299</td>\n",
       "      <td>-150.79400</td>\n",
       "      <td>0.55715</td>\n",
       "      <td>148.71490</td>\n",
       "      <td>-2.41587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>20.19082</td>\n",
       "      <td>-162.50028</td>\n",
       "      <td>-123.04788</td>\n",
       "      <td>-71.11772</td>\n",
       "      <td>-8.96605</td>\n",
       "      <td>-51.72176</td>\n",
       "      <td>30.53830</td>\n",
       "      <td>15.27979</td>\n",
       "      <td>-34.99486</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.13628</td>\n",
       "      <td>18.76005</td>\n",
       "      <td>46.07843</td>\n",
       "      <td>-309.69087</td>\n",
       "      <td>-24.52842</td>\n",
       "      <td>-35.79334</td>\n",
       "      <td>-774.53143</td>\n",
       "      <td>3.34849</td>\n",
       "      <td>-194.68101</td>\n",
       "      <td>-41.23842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "      <td>25.10092</td>\n",
       "      <td>-189.85543</td>\n",
       "      <td>-28.69605</td>\n",
       "      <td>-34.42398</td>\n",
       "      <td>24.64007</td>\n",
       "      <td>-55.86989</td>\n",
       "      <td>63.91339</td>\n",
       "      <td>17.88235</td>\n",
       "      <td>-3.39713</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.70478</td>\n",
       "      <td>40.14964</td>\n",
       "      <td>95.55738</td>\n",
       "      <td>-36.47506</td>\n",
       "      <td>-8.63102</td>\n",
       "      <td>-34.57157</td>\n",
       "      <td>-13.63610</td>\n",
       "      <td>8.25615</td>\n",
       "      <td>108.42127</td>\n",
       "      <td>3.51335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1          2          3         4         5         6   \\\n",
       "0  2007  25.23214 -232.77465  -37.51542 -40.34335  56.11564 -55.94831   \n",
       "1  2007  27.96974 -166.08713  -11.19265 -28.07397 -56.10902 -35.47258   \n",
       "2  2007  24.75152  -97.45055  -40.15226 -43.39929 -57.25665 -33.93026   \n",
       "3  2007  20.19082 -162.50028 -123.04788 -71.11772  -8.96605 -51.72176   \n",
       "4  2007  25.10092 -189.85543  -28.69605 -34.42398  24.64007 -55.86989   \n",
       "\n",
       "         7         8         9   ...        81         82         83  \\\n",
       "0  43.06882  15.46278 -38.67370  ... -15.64058  257.69408  113.59740   \n",
       "1  23.35854   7.19973 -36.81179  ...  21.49227  289.05914  -34.75972   \n",
       "2  -1.95605   0.93121   7.76578  ...  -5.96584  573.94557   11.83355   \n",
       "3  30.53830  15.27979 -34.99486  ... -73.13628   18.76005   46.07843   \n",
       "4  63.91339  17.88235  -3.39713  ...  -3.70478   40.14964   95.55738   \n",
       "\n",
       "          84        85         86         87       88         89        90  \n",
       "0  -90.14988 -13.41911  -72.59105 -185.49959  1.16272  -73.13128  -6.89193  \n",
       "1  -19.38242   2.44006  -67.78591  -46.62749  0.38383   98.98315  13.14364  \n",
       "2 -107.81947  -3.42495 -141.79299 -150.79400  0.55715  148.71490  -2.41587  \n",
       "3 -309.69087 -24.52842  -35.79334 -774.53143  3.34849 -194.68101 -41.23842  \n",
       "4  -36.47506  -8.63102  -34.57157  -13.63610  8.25615  108.42127   3.51335  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_csv('/home/ubuntu/data/msd_training_data_split.csv', sep=\",\", header=None)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2007\n",
       "1    2007\n",
       "2    2007\n",
       "3    2007\n",
       "4    2007\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = training_data.iloc[:, 0]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>25.23214</td>\n",
       "      <td>-232.77465</td>\n",
       "      <td>-37.51542</td>\n",
       "      <td>-40.34335</td>\n",
       "      <td>56.11564</td>\n",
       "      <td>-55.94831</td>\n",
       "      <td>43.06882</td>\n",
       "      <td>15.46278</td>\n",
       "      <td>-38.67370</td>\n",
       "      <td>-10.30987</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.64058</td>\n",
       "      <td>257.69408</td>\n",
       "      <td>113.59740</td>\n",
       "      <td>-90.14988</td>\n",
       "      <td>-13.41911</td>\n",
       "      <td>-72.59105</td>\n",
       "      <td>-185.49959</td>\n",
       "      <td>1.16272</td>\n",
       "      <td>-73.13128</td>\n",
       "      <td>-6.89193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>27.96974</td>\n",
       "      <td>-166.08713</td>\n",
       "      <td>-11.19265</td>\n",
       "      <td>-28.07397</td>\n",
       "      <td>-56.10902</td>\n",
       "      <td>-35.47258</td>\n",
       "      <td>23.35854</td>\n",
       "      <td>7.19973</td>\n",
       "      <td>-36.81179</td>\n",
       "      <td>-7.84188</td>\n",
       "      <td>...</td>\n",
       "      <td>21.49227</td>\n",
       "      <td>289.05914</td>\n",
       "      <td>-34.75972</td>\n",
       "      <td>-19.38242</td>\n",
       "      <td>2.44006</td>\n",
       "      <td>-67.78591</td>\n",
       "      <td>-46.62749</td>\n",
       "      <td>0.38383</td>\n",
       "      <td>98.98315</td>\n",
       "      <td>13.14364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>24.75152</td>\n",
       "      <td>-97.45055</td>\n",
       "      <td>-40.15226</td>\n",
       "      <td>-43.39929</td>\n",
       "      <td>-57.25665</td>\n",
       "      <td>-33.93026</td>\n",
       "      <td>-1.95605</td>\n",
       "      <td>0.93121</td>\n",
       "      <td>7.76578</td>\n",
       "      <td>4.96972</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.96584</td>\n",
       "      <td>573.94557</td>\n",
       "      <td>11.83355</td>\n",
       "      <td>-107.81947</td>\n",
       "      <td>-3.42495</td>\n",
       "      <td>-141.79299</td>\n",
       "      <td>-150.79400</td>\n",
       "      <td>0.55715</td>\n",
       "      <td>148.71490</td>\n",
       "      <td>-2.41587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20.19082</td>\n",
       "      <td>-162.50028</td>\n",
       "      <td>-123.04788</td>\n",
       "      <td>-71.11772</td>\n",
       "      <td>-8.96605</td>\n",
       "      <td>-51.72176</td>\n",
       "      <td>30.53830</td>\n",
       "      <td>15.27979</td>\n",
       "      <td>-34.99486</td>\n",
       "      <td>-5.25631</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.13628</td>\n",
       "      <td>18.76005</td>\n",
       "      <td>46.07843</td>\n",
       "      <td>-309.69087</td>\n",
       "      <td>-24.52842</td>\n",
       "      <td>-35.79334</td>\n",
       "      <td>-774.53143</td>\n",
       "      <td>3.34849</td>\n",
       "      <td>-194.68101</td>\n",
       "      <td>-41.23842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>25.10092</td>\n",
       "      <td>-189.85543</td>\n",
       "      <td>-28.69605</td>\n",
       "      <td>-34.42398</td>\n",
       "      <td>24.64007</td>\n",
       "      <td>-55.86989</td>\n",
       "      <td>63.91339</td>\n",
       "      <td>17.88235</td>\n",
       "      <td>-3.39713</td>\n",
       "      <td>4.55056</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.70478</td>\n",
       "      <td>40.14964</td>\n",
       "      <td>95.55738</td>\n",
       "      <td>-36.47506</td>\n",
       "      <td>-8.63102</td>\n",
       "      <td>-34.57157</td>\n",
       "      <td>-13.63610</td>\n",
       "      <td>8.25615</td>\n",
       "      <td>108.42127</td>\n",
       "      <td>3.51335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1          2          3         4         5         6         7   \\\n",
       "0  25.23214 -232.77465  -37.51542 -40.34335  56.11564 -55.94831  43.06882   \n",
       "1  27.96974 -166.08713  -11.19265 -28.07397 -56.10902 -35.47258  23.35854   \n",
       "2  24.75152  -97.45055  -40.15226 -43.39929 -57.25665 -33.93026  -1.95605   \n",
       "3  20.19082 -162.50028 -123.04788 -71.11772  -8.96605 -51.72176  30.53830   \n",
       "4  25.10092 -189.85543  -28.69605 -34.42398  24.64007 -55.86989  63.91339   \n",
       "\n",
       "         8         9         10  ...        81         82         83  \\\n",
       "0  15.46278 -38.67370 -10.30987  ... -15.64058  257.69408  113.59740   \n",
       "1   7.19973 -36.81179  -7.84188  ...  21.49227  289.05914  -34.75972   \n",
       "2   0.93121   7.76578   4.96972  ...  -5.96584  573.94557   11.83355   \n",
       "3  15.27979 -34.99486  -5.25631  ... -73.13628   18.76005   46.07843   \n",
       "4  17.88235  -3.39713   4.55056  ...  -3.70478   40.14964   95.55738   \n",
       "\n",
       "          84        85         86         87       88         89        90  \n",
       "0  -90.14988 -13.41911  -72.59105 -185.49959  1.16272  -73.13128  -6.89193  \n",
       "1  -19.38242   2.44006  -67.78591  -46.62749  0.38383   98.98315  13.14364  \n",
       "2 -107.81947  -3.42495 -141.79299 -150.79400  0.55715  148.71490  -2.41587  \n",
       "3 -309.69087 -24.52842  -35.79334 -774.53143  3.34849 -194.68101 -41.23842  \n",
       "4  -36.47506  -8.63102  -34.57157  -13.63610  8.25615  108.42127   3.51335  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = training_data.iloc[:, 1:]\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same with the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/home/ubuntu/data/msd_test_data_split.csv', sep=\",\", header=None)\n",
    "y_test = test_data.iloc[:, 0]\n",
    "x_test = test_data.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:45:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=3, min_child_weight=1, missing=None, n_estimators=20,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(n_estimators=20)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions and evaluate the model with the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243.45763709390334"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(x_test)\n",
    "np.sqrt(mean_squared_error(preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated XGBoost\n",
    "We will now discuss running XGBoost in the federated setting.\n",
    "\n",
    "### Edit hosts.config \n",
    "The `hosts.config` file should contain the IPs and ports of all workers in the federation. After loading in the `hosts.config` file, modify it to contain the IPs of your new friends! Then write the new addresses back to the file by adding a magic to the top of the cell:\n",
    "\n",
    "`%%writefile hosts.config`\n",
    "\n",
    "Make sure to delete the `# %load hosts.config` line from the cell before saving it. We'll be continually using the `%load` and `%%writefile` magics in this tutorial to edit files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hosts.config\n"
     ]
    }
   ],
   "source": [
    "%%writefile hosts.config\n",
    "35.167.132.178:22\n",
    "34.222.205.126:22\n",
    "34.222.177.218:22\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the Training/Eval Script\n",
    "We will now modify the script that will be run for training and evaluation. Load it in by running the following cell. The contents of the script should appear in the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tutorial.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tutorial.py\n",
    "from FederatedXGBoost import FederatedXGBoost\n",
    "\n",
    "# Instantiate a FederatedXGBoost instance\n",
    "fxgb = FederatedXGBoost()\n",
    "\n",
    "# Get number of federating parties\n",
    "print(fxgb.get_num_parties())\n",
    "\n",
    "# Load training data\n",
    "fxgb.load_training_data('/home/ubuntu/data/msd_training_data_split.csv')\n",
    "\n",
    "# Train a model\n",
    "params = {'max_depth': 3, 'min_child_weight': 1.0, 'lambda': 1.0}\n",
    "num_rounds = 50\n",
    "fxgb.train(params, num_rounds)\n",
    "\n",
    "# Save the model\n",
    "fxgb.save_model(\"tutorial_model.model\")\n",
    "\n",
    "# Load the test data\n",
    "fxgb.load_test_data('/home/ubuntu/data/msd_test_data_split.csv')\n",
    "\n",
    "# Evaluate the model\n",
    "print(fxgb.eval())\n",
    "\n",
    "# Get predictions\n",
    "ypred = fxgb.predict()\n",
    "\n",
    "# Shutdown\n",
    "fxgb.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Job\n",
    "After modifying the script, we can start our job! We use the `start_job.sh` script with the given options to do so.\n",
    "\n",
    "The following flags must be specified when running the script.\n",
    "\n",
    "`./start_job.sh`\n",
    "\n",
    "* `-m | --worker-memory` string, specified as \"<memory>g\", e.g. 3g\n",
    "    * Amount of memory on workers allocated to job\n",
    "* `-p | --num-parties` integer\n",
    "    * Number of parties in the federation\n",
    "* `-d | --dir` string\n",
    "    * Path to created subdirectory containing job script, e.g. `/home/ubuntu/mc2/federated-xgboost/risecamp`\n",
    "* `-j | --job` string\n",
    "    * Path to job script. This should be the parameter passed into the `--dir` option concatenated with the job script file name, e.g. `/home/ubuntu/mc2/federated-xgboost/risecamp/tutorial.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-18 08:31:27,924 INFO start listen on 172.31.41.140:9091\n",
      "2019-09-18 08:31:27,932 INFO rsync /home/ubuntu/mc2/federated-xgboost/risecamp/ -> 35.167.132.178:/home/ubuntu/mc2/federated-xgboost/risecamp/\n",
      "2019-09-18 08:31:27,932 INFO rsync /home/ubuntu/mc2/federated-xgboost/risecamp/ -> 34.222.205.126:/home/ubuntu/mc2/federated-xgboost/risecamp/\n",
      "2019-09-18 08:31:27,932 INFO rsync /home/ubuntu/mc2/federated-xgboost/risecamp/ -> 34.222.177.218:/home/ubuntu/mc2/federated-xgboost/risecamp/\n",
      "2019-09-18 08:31:30,319 INFO @tracker All of 3 nodes getting started\n",
      "3\n",
      "[08:31:46] WARNING: /workspace/src/learner.cc:622: Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[08:31:46] Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[0]\teval-rmse:9.287228\n",
      "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:614: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"because it will generate extra copies and increase memory consumption\")\n",
      "3\n",
      "[08:31:46] WARNING: /workspace/src/learner.cc:622: Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[08:31:46] Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[0]\teval-rmse:9.287228\n",
      "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:614: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"because it will generate extra copies and increase memory consumption\")\n",
      "2019-09-18 08:32:10,584 INFO @tracker All nodes finishes job\n",
      "3\n",
      "[08:31:46] WARNING: /workspace/src/learner.cc:622: Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[08:31:46] Tree method is automatically selected to be 'approx' for distributed training.\n",
      "[0]\teval-rmse:9.287228\n",
      "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:614: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"because it will generate extra copies and increase memory consumption\")\n",
      "2019-09-18 08:32:10,584 INFO @tracker 40.26437306404114 secs between node start and job finish\n"
     ]
    }
   ],
   "source": [
    "!./start_job.sh -p 3 -m 3g -d /home/ubuntu/mc2/federated-xgboost/risecamp/ -j /home/ubuntu/mc2/federated-xgboost/risecamp/tutorial.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
